

import cv2
import numpy as np
import glob
import os
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# from moviepy.editor import VideoFileClip

# images = glob.glob( os.path.join('.','camera_cal','calibration*.jpg'))
#
#
# objpoints = []
# imgpoints = []
#
# objp = np.zeros((6*9,3), np.float32)
# objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)
#
# for fname in images:
#     img = mpimg.imread(fname)
#
#     gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
#
#     ret, corners = cv2.findChessboardCorners(gray, (9,6), None)
#
#     if ret == True:
#         imgpoints.append(corners)
#         objpoints.append(objp)
#
#         img = cv2.drawChessboardCorners(img, (9,6), corners, ret)
#         # plt.imshow(img)
#         # plt.show()
#
#
# ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1],None,None)
#
# img = cv2.imread(os.path.join('.','camera_cal','calibration1.jpg'))
#
# dst = cv2.undistort(img,mtx,dist,None,mtx)
# # plt.imshow(dst)
# # plt.show()
#
#
# # detect and draw a single image's corners
# # img = cv2.imread(os.path.join('.','camera_cal','calibration2.jpg'))
# # objpoints = []
# # imgpoints = []
# #
# # objp = np.zeros((6*9,3), np.float32)
# # objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)
# #
# # gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
# #
# # ret, corners = cv2.findChessboardCorners(gray, (9,6), None)
# #
# # if ret == True:
# #     imgpoints.append(corners)
# #     objpoints.append(objp)
# #
# #     img = cv2.drawChessboardCorners(img, (9,6), corners, ret)
# #     plt.imshow(img)
# #     plt.show()
#
#
# ############## Part 2 Piplining
#
# def mag_thresh(img, sobel_kernel=3, mag_thresh=(0, 255)):
#     # Convert to grayscale
#     gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
#     # Take both Sobel x and y gradients
#     sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)
#     sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)
#     # Calculate the gradient magnitude
#     gradmag = np.sqrt(sobelx**2 + sobely**2)
#     # Rescale to 8 bit
#     scale_factor = np.max(gradmag)/255
#     gradmag = (gradmag/scale_factor).astype(np.uint8)
#     # Create a binary image of ones where threshold is met, zeros otherwise
#     binary_output = np.zeros_like(gradmag)
#     binary_output[(gradmag >= mag_thresh[0]) & (gradmag <= mag_thresh[1])] = 1
#
#     # Return the binary image
#     return binary_output
#
# # Define a function to threshold an image for a given range and Sobel kernel
# def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):
#     # Grayscale
#     gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
#     # Calculate the x and y gradients
#     sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)
#     sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)
#     # Take the absolute value of the gradient direction,
#     # apply a threshold, and create a binary image result
#     absgraddir = np.arctan2(np.absolute(sobely), np.absolute(sobelx))
#     binary_output =  np.zeros_like(absgraddir)
#     binary_output[(absgraddir >= thresh[0]) & (absgraddir <= thresh[1])] = 1
#
#     # Return the binary image
#     return binary_output
#
# def my_abs_sobel_thresh(img, orient='x', thresh_min=0, thresh_max=255):
#     def scale_sobel(input):
#         abs_sobelx = np.absolute(input)
#         return np.uint8(255 * abs_sobelx / np.max(abs_sobelx))
#
#     gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
#     sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0)
#     sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1)
#     scaled_sobel = scale_sobel(sobelx) if orient == 'x' else scale_sobel(sobely)
#     sxbinary = np.zeros_like(scaled_sobel)
#     sxbinary[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1
#     # plt.imshow(sxbinary, cmap='gray')
#     return sxbinary
#
# def abs_sobel_thresh(img, orient='x', sobel_kernel=3, thresh=(0,255)):
#     thresh_min = thresh[0]
#     thresh_max = thresh[1]
#     # Convert to grayscale
#     gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
#     # Apply x or y gradient with the OpenCV Sobel() function
#     # and take the absolute value
#     if orient == 'x':
#         abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0,ksize=sobel_kernel))
#     if orient == 'y':
#         abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1,ksize=sobel_kernel))
#     # Rescale back to 8 bit integer
#     scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))
#     # Create a copy and apply the threshold
#     binary_output = np.zeros_like(scaled_sobel)
#     # Here I'm using inclusive (>=, <=) thresholds, but exclusive is ok too
#     binary_output[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1
#
#     # Return the result
#     return binary_output
#
# def get_combined_gradient(img):
#     # Choose a Sobel kernel size
#     ksize = 3  # Choose a larger odd number to smooth gradient measurements
#
#     # Apply each of the thresholding functions
#     gradx = abs_sobel_thresh(img, orient='x', sobel_kernel=ksize, thresh=(100, 255))
#     grady = abs_sobel_thresh(img, orient='y', sobel_kernel=ksize, thresh=(100, 255))
#     mag_binary = mag_thresh(img, sobel_kernel=ksize, mag_thresh=(50, 255))
#     dir_binary = dir_threshold(img, sobel_kernel=ksize, thresh=(0.7, 1.3))
#     dir_binary2 = np.uint8(255 * dir_binary / np.max(dir_binary))
#     # plt.imshow(dir_binary2)
#     # plt.show()
#     combined = np.zeros_like(dir_binary)
#     combined[((gradx == 1) & (grady == 1)) | ((mag_binary == 1) & (dir_binary == 1))] = 1
#     combined = np.uint8(255 * combined / np.max(combined))
#
#     return  combined
#
# def get_combined(img):
#     # Convert to HLS color space and separate the S channel
#     # Note: img is the undistorted image
#     hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)
#     s_channel = hls[:, :, 2]
#
#     # Grayscale image
#     # NOTE: we already saw that standard grayscaling lost color information for the lane lines
#     # Explore gradients in other colors spaces / color channels to see what might work better
#     gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
#
#     # Sobel x
#     sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0)  # Take the derivative in x
#     abs_sobelx = np.absolute(sobelx)  # Absolute x derivative to accentuate lines away from horizontal
#     scaled_sobel = np.uint8(255 * abs_sobelx / np.max(abs_sobelx))
#
#     # Threshold x gradient
#     thresh_min = 20
#     thresh_max = 100
#     sxbinary = np.zeros_like(scaled_sobel)
#     sxbinary[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1
#
#     sxbinary = get_combined_gradient(img)
#
#     # Threshold color channel
#     s_thresh_min = 170
#     s_thresh_max = 255
#     s_binary = np.zeros_like(s_channel)
#     s_binary[(s_channel >= s_thresh_min) & (s_channel <= s_thresh_max)] = 1
#
#
#
#     # Stack each channel to view their individual contributions in green and blue respectively
#     # This returns a stack of the two binary images, whose components you can see as different colors
#     color_binary = np.dstack((np.zeros_like(sxbinary), sxbinary, s_binary))
#
#     # Combine the two binary thresholds
#     combined_binary = np.zeros_like(sxbinary)
#     combined_binary[(s_binary == 1) | (sxbinary == 1)] = 1
#     # plt.imshow(combined_binary)
#     # plt.show()
#     return combined_binary
#
#
# def pipeline(img, s_thresh=(170, 255), sx_thresh=(20, 100)):
#     combined_binary = get_combined(img)
#     return combined_binary
#
# def process_image(img):
#     img = cv2.undistort(img,mtx,dist,None,mtx)
#     result = pipeline(img)
#     return np.uint8(result*255.0)
#
# # white_output = 'test_videos_output/solidWhiteRight.mp4'
# #
# # clip1 = VideoFileClip("test_videos/solidWhiteRight.mp4")
# # white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!
# # white_clip.write_videofile(white_output, audio=False)
#
# test_image_location = ".\\test_images\\straight_lines1.jpg"
# output_image_location = ".\\output_images\\output1.jpg"
#
# test_image = cv2.imread(test_image_location)
# output_image = process_image(test_image)
# # plt.imshow(output_image)
# # plt.show()
# cv2.imwrite(output_image_location,output_image)


images = glob.glob('./test_images/*.jpg')

for i in range(len(images)):
    img = cv2.imread(images[i])
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    # top_left = [562,470]
    # top_right = [721,470]
    top_left = [560, 470]
    top_right = [720, 470]
    bottom_right = [950,620]
    bottom_left = [350,620]
    pts = np.array([bottom_left,bottom_right,top_right,top_left])

    # plt.imshow(img)
    # plt.plot(top_left[0],top_left[1],'.')
    # plt.plot(top_right[0], top_right[1], '.')
    # plt.plot(bottom_right[0], bottom_right[1], '.')
    # plt.plot(bottom_left[0], bottom_left[1], '.')
    # plt.show()

    top_left_dst = [320,0]
    top_right_dst = [980,0]
    bottom_right_dst = [980,720]
    bottom_left_dst = [320,720]
    dst_pts = np.array([bottom_left_dst, bottom_right_dst, top_right_dst, top_left_dst])

    ## you can plot this and see that lines are properly chosen
    ## cv2.polylines(img,[pts],True,(255,0,0), 5)
    ## cv2.polylines(img,[dst_pts],True,(0,0,255), 5)

    pts = np.float32(pts.tolist())
    dst_pts = np.float32(dst_pts.tolist())

    ## M is the transformation matrix
    M = cv2.getPerspectiveTransform(pts, dst_pts)
    Minv = cv2.getPerspectiveTransform(dst_pts, pts)

    fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (40, 15))
    image_size = (img.shape[1], img.shape[0])
    warped = cv2.warpPerspective(img, M, dsize = image_size, flags = cv2.INTER_LINEAR)
    ax1.imshow(img)
    ax1.plot(top_left[0], top_left[1], '.')
    ax1.plot(top_right[0], top_right[1], '.')
    ax1.plot(bottom_right[0], bottom_right[1], '.')
    ax1.plot(bottom_left[0], bottom_left[1], '.')
    ax2.imshow(warped)
    plt.show()













